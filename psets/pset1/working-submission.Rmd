---
title: "MY457: Problem Set One"
date:  "`r format(Sys.time(), '%a/%d/%b')`"
author: "Peter Tiborcz"
always_allow_html: true
output: 
  bookdown::pdf_document2:
    toc: false
---

```{r setup, include = FALSE}
# this chunk contains code that sets global options for the entire .Rmd. 
# we use include=FALSE to suppress it from the top of the document, but it will still appear in the appendix. 
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE, linewidth=60)

# you can include your libraries here:
library(tidyverse)
#install.packages("report")
library(report)

# and any other options in R:
options(scipen=999)

```

# Concepts

Consider a simple study of the effect of a treatment: $$
D_i \in \{0,1\} \text{ on } Y_i \text{ for all } i \in \{1,2,3,\dots,N\}$$

##

$Y_{i1}$  represents the potential outcome for unit  if they receive treatment (D=1). This situation of $Y_{i}$ having the same quantity as $Y_{i1}$ is only possible when the unit i is treated.

##

The difference between $E[Y_{i0} \mid D_i = 1]$ and $E[Y_{i0} \mid D_i = 0]$ is that the first one cannot be observed, while the second one we can observe.

I would expect these quantities to be equal when we randomly select the units to be treated. This is because the treatment is randomly assigned, so the potential outcomes are also randomly assigned.

We would expect these to be unequal when the treatment is not randomly assigned. This is because the potential outcomes are not randomly assigned, so the treatment is not randomly assigned.

##
Random assignment ensures that the treatment and control groups are statistically identical on average before treatment. This allows us to estimate the Average Treatment Effect (ATE).

Since randomization removes systematic differences between groups, any difference in outcomes can be attributed to the treatment itself rather than confounding factors.


\clearpage

# Simulations

##

The following R code generates a dataset with 500 observations, a treatment effect of 5000, and several characteristics:

```{r generate-data}
set.seed(123)
n <- 500
tau <- 5000

data <- data.frame(
Age = rnorm(n, mean = 42, sd = 10),
Education = sample(1:4, n, replace = TRUE),
Y0 = rnorm(n, mean = 50000, sd = 10000)
)
data <- data %>% mutate(
Y1 = Y0 + tau,
D = sample(c(0, 1), n, replace = TRUE),
Y = ifelse(D== 1, Y1, Y0)
)

head(data, 10)
```

  - Age is generated from a normal distribution with a mean of 42 and a standard deviation of 10.

  - Education is randomly assigned one of four categories.

  - Y0 represents the baseline outcome (without treatment), drawn from a normal distribution with a mean of 50,000.

  - Y1 is the potential outcome if treated, which is Y0 + tau.

  - D is the treatment indicator, randomly assigned.

  - Y is the observed outcome, which depends on D. 

Because we simulated the data we can also simulate both potential outcomes for each observation which are the Y1 and Y0 variables. We set the seed to 123 to ensure reproducibility.

##

To ensure that randomization successfully balances covariates, we conduct t-tests comparing Age and Education across treatment and control groups.

```{r explore-data, warning=FALSE}
# Print results using report package
report::report(t.test(Age ~ D, data = data))
report::report(t.test(Education ~ D, data = data))
```

Both Age and Education are balanced across treatment (D=1) and control (D=0) groups, as there are no statistically significant differences in means. This supports the randomization assumption that the two groups are comparable.

##

To figure out the difference in means between the potential outcomes $Y_0$ and $Y_1$ we can use the following code:

```{r difference-in-means}
# Calculate the difference in means between Y1 and Y0
diffINmeans <- mean(data$Y[data$D==1]) - mean(data$Y[data$D==0])
diffINmeans
```

Given that the treatment effect (tau) was set to 5000, but the estimated effect is 4181.018, the estimate is  lower than the true effect. The discrepancy may be due to randomization variability or sampling variability.

```{r t-test-linear-regression}
report::report(t.test(Y ~ D, data = data))
```

##

We visualize the outcome distribution across treatment groups:

```{r visualise-the-distribution of-Y-by-treatment-status}
# Plot the distribution of Y conditional on D
ggplot(data, aes(x = Y, fill = as.factor(D))) +
  geom_density(alpha = 0.5) +
  labs(title = "Distribution of Y by Treatment Status",
       x = "Outcome (Y)",
       y = "Density",
       fill = "Treatment (D)") +
  theme_minimal()
```

We then estimate the ATE using two approaches:

```{r linear-regression}
diffInMeans <- mean(data$Y[data$D == 1]) - mean(data$Y[data$D == 0])
print(diffInMeans)

lm_model <- lm(Y ~ D, data = data)
summary(lm_model)

```

Difference-in-means and OLS regression should produce similar estimates if randomization is successful.  

##

We run 1,000 simulations to verify that our ATE estimate is not due to chance:

```{r simulate-ate}
# Set parameters
n_simulations <- 1000
tau <- 5000
n <- 500

# Initialize vector to store deviations
ate_differences <- numeric(n_simulations)

# Run 1,000 simulations
for (i in 1:n_simulations) {
  # Generate new random dataset
  data <- data.frame(
    Age = rnorm(n, mean = 42, sd = 10),
    Education = sample(1:4, n, replace = TRUE),
    Y0 = rnorm(n, mean = 50000, sd = 10000)
  )
  
  # Apply intervention effects
  data <- data %>%
    mutate(
      Y1 = Y0 + tau,
      D = sample(c(0, 1), n, replace = TRUE),  # Randomly assign treatment
      Y = ifelse(D == 1, Y1, Y0)               # Observed outcome
    )
  
  # Estimate ATE (difference-in-means)
  estimated_ate <- mean(data$Y[data$D == 1]) - mean(data$Y[data$D == 0])
  
  # Store the difference from true ATE
  ate_differences[i] <- estimated_ate - tau
}

# Compute the mean of the differences
mean_diff <- mean(ate_differences)

# Plot histogram of ATE differences
ggplot(data.frame(ate_differences), aes(x = ate_differences)) +
  geom_histogram(color = "black", fill = "blue", bins = 30, alpha = 0.7) +
  geom_vline(aes(xintercept = mean_diff), color = "red", linetype = "dashed") +
  labs(
    title = "Distribution of Estimated ATE Differences",
    x = "Estimated ATE - True ATE",
    y = "Frequency"
  ) +
  theme_minimal()
```

After simulating 1000 data generations, the estimated ATE averages really close to 0 suggesting an unbiased estimation.

# Replication

##

We begin by loading the dataset and creating a new binary variable sd_onefem2014, which takes the value 1 if at least one woman was elected in 2014, and 0 otherwise:

```{r import-data}
#install.packages("readstata13")
library(readstata13)

# Load the dta data
electwomen_data <- read.dta13("how_to_elect_more_women.dta")

# Create sd_onefem2014 dummy variable from prop_sd_fem2014
electwomen_data <- electwomen_data %>%
  mutate(sd_onefem2014 = ifelse(prop_sd_fem2014 > 0, 1, 0))

colnames(electwomen_data)
```

This transformation allows us to assess how treatment conditions impact the likelihood of electing at least one woman. We can printed out the column names to ensure that the new variable was created.

##

To verify the distribution of precincts across conditions, we compute the count and proportion of precincts in each group:

```{r balance-check}
# Ensure there are no missing values
data <- electwomen_data %>% mutate(prop_sd_fem2014 = ifelse(is.na(prop_sd_fem2014), 0, prop_sd_fem2014))

# Group by 'condition' and calculate proportions correctly
condition_summary <- electwomen_data %>%
  group_by(condition) %>%
  summarise(
    precinct_count = n(),  # Number of precincts in each condition group
    sum_fem2014 = sum(prop_sd_fem2014, na.rm = TRUE),  # Sum of elected women proportion
    proportion_fem2014 = sum_fem2014 / sum(data$prop_sd_fem2014, na.rm = TRUE)  # Proportion per condition
  )

# Print results
print(condition_summary)
```

The summary table confirms whether randomization achieved balanced group sizes and provides insight into how treatment affected womenâ€™s representation.

##

To check if treatment groups were balanced, we conduct pairwise t-tests on two pre-treatment variables: agecat (age category) and race.

```{r balance-check-t-test}
#test balance in pre-treatment variables of "agecat" and "race" betwen different conditions
# Define pre-treatment variables
pre_treatment_vars <- c("agecat", "race")

# Define unique conditions (excluding NA)
conditions <- c("Control", "Demand", "Supply", "Supply+Demand")

# Function to perform pairwise t-tests
perform_t_test <- function(var, group1, group2) {
  test_result <- electwomen_data %>%
    filter(condition %in% c(group1, group2)) %>%
    t.test(reformulate("condition", var), data = .)
  
  cat("\nT-test for", var, "between", group1, "and", group2, "\n")
  print(test_result)
}

# Run t-tests for each variable between control and each treatment group
for (var in pre_treatment_vars) {
  for (group in conditions[conditions != "Control"]) {
    perform_t_test(var, "Control", group)
  }
}
```

No t test is significant, so we can say that the randomization was successful.

##

To measure the effect of each intervention, we estimate the ATE using separate regressions:

```{r estimate-ate}
# Function to run linear regression for ATE estimation
estimate_ate <- function(treatment_group) {
  # Subset to only include Control and the current treatment group
  subset_data <- electwomen_data %>%
    filter(condition %in% c("Control", treatment_group)) %>%
    mutate(treatment = ifelse(condition == treatment_group, 1, 0))  # Convert to binary

  # Run linear regression
  model <- lm(sd_onefem2014 ~ treatment, data = subset_data)
  
  # Print results
  cat("\nATE Estimate for", treatment_group, "vs. Control:\n")
  print(summary(model))
}

# Run regressions for each treatment group
treatment_groups <- c("Demand", "Supply", "Supply+Demand")

for (treatment in treatment_groups) {
  estimate_ate(treatment)
}
```

This method isolates the effect of each intervention. The results show that each treatment increased the likelihood of elect

##

Instead of separate regressions, we now estimate all treatment effects simultaneously using a single regression model:

```{r estimate-ate-simultaneously}
# Create dummy variables for each treatment group
electwomen_data <- electwomen_data %>%
  mutate(
    treatment_demand = ifelse(condition == "Demand", 1, 0),
    treatment_supply = ifelse(condition == "Supply", 1, 0),
    treatment_supply_demand = ifelse(condition == "Supply+Demand", 1, 0)
  )

# Run a single regression with all treatment groups
full_model <- lm(sd_onefem2014 ~ treatment_demand + treatment_supply + treatment_supply_demand, data = electwomen_data)

# Print results
summary(full_model)
```

This model allows us to compare the effects of all treatments while accounting for potential shared variance across groups. After simultaneously estimating the ATE of the different treatments we found that that the coefficients of each individual treatment are the exactly the same as when we estimated them individually. The intercept is also the same. Similarly we found that the t test also resulted in the same results as before. Doing them simultaneously did not resulst any changes in the results.

# Code appendix

```{r ref.label = knitr::all_labels(), echo=TRUE, eval=FALSE}
# this chunk generates the complete code appendix. 
# eval=FALSE tells R not to re-run (``evaluate'') the code here. 
```
